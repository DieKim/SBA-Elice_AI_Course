{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "StratifiedKFold_Categorical_Crossentropy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "384px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DieKim/SBA-Elice_Project_NLP/blob/main/sba_project_emoing/StratifiedKFold_Categorical_Crossentropy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFbqXlnPasfC"
      },
      "source": [
        "# Bidirectional + StratifiedKFold + Categorical Crossentropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy5StYzhasfL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuFsHIR7asf1"
      },
      "source": [
        "## 3. 딥러닝 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8IVW9dIasf2"
      },
      "source": [
        "### 3-1. 모델 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30EMNnOLasf2"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM, SimpleRNN, Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing import sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGIkXFG4asf2"
      },
      "source": [
        "sequence_length = 35 # max(num_token_per_sentence)\n",
        "vocabulary_size = len(tokenizer.word_index)+1 # 10376\n",
        "embedding_dim = 256"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRv8P8pQwnQU",
        "outputId": "56a45ff4-1e5a-40f5-d20f-f1c11b959590"
      },
      "source": [
        "## https://www.tensorflow.org/tutorials/text/text_classification_rnn\n",
        "\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "\n",
        "model = Sequential([            \n",
        "  Embedding(vocabulary_size, embedding_dim, mask_zero=True),\n",
        "  Bidirectional(LSTM(64,  return_sequences=True)),\n",
        "  Bidirectional(LSTM(32)),\n",
        "  Dense(64, activation='relu'),\n",
        "  Dropout(0.5),\n",
        "  Dense(1, activation = 'softmax')\n",
        "])\n",
        "\n",
        "# 모델구조보기\n",
        "print(model.summary())\n",
        "\n",
        "## 모델 compile option주기\n",
        "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, None, 256)         2969088   \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, None, 128)         164352    \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 64)                41216     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 3,178,881\n",
            "Trainable params: 3,178,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4dpX3tyasf4"
      },
      "source": [
        "### 3-2. 데이터 split 및 학습 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dS0Cg9SKNqV8",
        "outputId": "a6bb9abe-f233-4f84-a833-8144be34c106"
      },
      "source": [
        "print(X_train_pad.shape)\n",
        "print(Y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 35)\n",
            "(20000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcd-HIjmBwuE",
        "outputId": "ef9907e3-a859-477c-81ca-e1eee465d98c"
      },
      "source": [
        "# to split train/test datasets having equal classes proportion >> StratifiedKFold \n",
        "from sklearn.model_selection import StratifiedKFold \n",
        "\n",
        "skf = StratifiedKFold(shuffle=True, random_state=42) # n_splits = 5\n",
        "\n",
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "fold_no = 1\n",
        "for train_idx, test_idx in skf.split(X_train_pad, Y_train):\n",
        "  # print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = X_train_pad[train_idx], X_train_pad[test_idx], Y_train[train_idx], Y_train[test_idx]\n",
        "  \n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  \n",
        "  # Fit data to model\n",
        "  history = model.fit(X_train_pad[train_idx], Y_train[train_idx], batch_size=64, epochs=10)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(X_train_pad[test_idx], Y_train[test_idx], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 49s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1340\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1304\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1370\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1330\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1297\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1339\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1401\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1401\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1283\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1388\n",
            "Score for fold 1: loss of 0.0; accuracy of 13.54999989271164%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 11s 43ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1355\n",
            "Score for fold 2: loss of 0.0; accuracy of 13.525000214576721%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Score for fold 3: loss of 0.0; accuracy of 13.54999989271164%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Score for fold 4: loss of 0.0; accuracy of 13.54999989271164%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 2/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 3/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 4/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 5/10\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 6/10\n",
            "250/250 [==============================] - 11s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 7/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 8/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 9/10\n",
            "250/250 [==============================] - 10s 41ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Epoch 10/10\n",
            "250/250 [==============================] - 10s 42ms/step - loss: 0.0000e+00 - accuracy: 0.1354\n",
            "Score for fold 5: loss of 0.0; accuracy of 13.54999989271164%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.0 - Accuracy: 13.54999989271164%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.0 - Accuracy: 13.525000214576721%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.0 - Accuracy: 13.54999989271164%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.0 - Accuracy: 13.54999989271164%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.0 - Accuracy: 13.54999989271164%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 13.544999957084656 (+- 0.009999871253967285)\n",
            "> Loss: 0.0\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXcfr8Wwasf5"
      },
      "source": [
        "### 3-3. 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEqVgvdxPZca"
      },
      "source": [
        "# 데이터셋 불러오기\n",
        "df_score = pd.read_csv('/content/drive/MyDrive/sentimental_analysis_project/data/score.csv',header=0, sep=';',names=['Sentence'],encoding='utf-8')\n",
        "stemming_sentence_score = []\n",
        "\n",
        "for sentence in df_score['Sentence']:\n",
        "    ## training데이터에서 했던것처럼, word_tokenizer와 stemmer를 사용하여 word token sequence로 만들어주세요\n",
        "    word_token = word_tokenize(sentence) # toknize\n",
        "    word_token = [word for word in word_token if not word in stop_words] # remove stopwords\n",
        "    word_token = [stemmer.stem(word) for word in word_token] # stemming(어간추출)\n",
        "    \n",
        "    stemming_sentence_score.append(word_token)\n",
        "\n",
        "## stemming_sentence_score,를 bow로 표현하기\n",
        "X_score = tokenizer.texts_to_sequences(stemming_sentence_score)\n",
        "\n",
        "## X_score를 padding을 붙여 일정길이로 만들어주기\n",
        "X_score_pad = pad_sequences(X_score, maxlen=35, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEmICwx8SVxZ",
        "outputId": "f3c05e0b-e6af-49f5-cc54-87cedce03294"
      },
      "source": [
        "# 모델에서 라벨 추측하기\n",
        "score_prediction = model.predict(X_score_pad)\n",
        "\n",
        "score_prediction = pd.Series(score_prediction.flatten())\n",
        "score_prediction.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    1000\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHQldljHLVzI"
      },
      "source": [
        "# 결과값 저장 \n",
        "submission_df = pd.DataFrame({\"Emotion\" : score_prediction_label})\n",
        "submission_df\n",
        "\n",
        "submission_df.to_csv('/content/drive/MyDrive/sentimental_analysis_project/submission.csv', index=False,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijKAHRAoxQ3u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
